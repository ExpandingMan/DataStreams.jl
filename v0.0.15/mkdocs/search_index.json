{
    "docs": [
        {
            "location": "/", 
            "text": "DataStreams.jl\n\n\nThe \nDataStreams.jl\n package aims to define a generic and performant framework for the transfer of \"table-like\" data. (i.e. data that can, at least in some sense, be described by rows and columns).\n\n\nThe framework achieves this by defining interfaces (i.e. a group of methods) for \nData.Source\n types and methods to describe how they \"provide\" data; as well as \nData.Sink\n types and methods around how they \"receive\" data. This allows \nData.Source\ns and \nData.Sink\ns to implement their interfaces separately, without needing to be aware of each other. The end result is an ecosystem of packages that \"automatically\" talk with each other, with adding an additional package not requiring changes to existing packages.\n\n\nPackages can have a single julia type implement both the \nData.Source\n and \nData.Sink\n interfaces, or two separate types can implement them separately. For examples of interface implementations, see some of the packages below:\n\n\nData.Source\n implementations:\n\n\n\n\nCSV.Source\n\n\nSQLite.Source\n\n\nDataFrame\n\n\nODBC.Source\n\n\n\n\nData.Sink\n implementations:\n\n\n\n\nCSV.Sink\n\n\nSQLite.Sink\n\n\nDataFrame\n\n\nODBC.Sink\n\n\n\n\n\n\nData.Source\n Interface\n\n\nThe \nData.Source\n interface requires the following definitions, where \nMyPkg\n would represent a package wishing to implement the interface:\n\n\n\n\nData.schema(::MyPkg.Source) =\n Data.Schema\n; get the \nData.Schema\n of a \nData.Source\n. Typically the \nSource\n type will store the \nData.Schema\n directly, but this isn't strictly required. See \n?Data.Schema\n or docs below for more information on \nData.Schema\n\n\nData.isdone(::MyPkg.Source, row, col) =\n Bool\n; indicates whether the \nData.Source\n will be able to provide a value at a given a \nrow\n and \ncol\n.\n\n\n\n\nOptional definition:\n\n\n\n\nData.reference(::MyPkg.Source) =\n Vector{UInt8}\n; Sometimes, a \nSource\n needs the \nSink\n to keep a reference to memory to keep a data structure valid. A \nSource\n can implement this method to return a \nVector{UInt8}\n that the \nSink\n will need to handle appropriately.\n\n\n\n\nA \nData.Source\n also needs to \"register\" the type (or types) of streaming it supports. Currently defined streaming types in the DataStreams framework include:\n\n\n\n\nData.Field\n: a field is the intersection of a specific row and column; this type of streaming will traverse the \"table\" structure by row, accessing each column on each row\n\n\nData.Column\n: this type of streaming will provide entire columns at a time\n\n\n\n\nA \nData.Source\n formally supports \nfield-based\n streaming by defining the following:\n\n\n\n\nData.streamtype(::Type{MyPkg.Source}, ::Type{Data.Field}) = true\n; declares that \nMyPkg.Source\n supports field-based streaming\n\n\nData.getfield{T}(::MyPkg.Source, ::Type{Nullable{T}}, row, col) =\n Nullable{T}\n; returns a value of type \nNullable{T}\n given a specific \nrow\n and \ncol\n from \nMyPkg.Source\n\n\nData.getfield{T}(::MyPkg.Source, ::Type{T}, row, col) =\n T\n; returns a value of type \nT\n given a specific \nrow\n and \ncol\n from \nMyPkg.Source\n\n\n\n\nAnd for column-based streaming:\n\n\n\n\nData.streamtype(::Type{MyPkg.Source}, ::Type{Data.Column}) = true\n\n\nData.getcolumn{T}(::Data.Source, ::Type{T}, col) =\n Vector{T}\n; Given a type \nT\n, returns column # \ncol\n of a \nData.Source\n as a \nVector{T}\n\n\nData.getcolumn{T}(::Data.Source, ::Type{Nullable{T}}, col) =\n NullableVector{T}\n; Given a type \nNullable{T}\n, returns column # \ncol\n of a \nData.Source\n as a \nNullableVector{T}\n\n\n\n\n\n\nData.Sink\n Interface\n\n\nSimilar to a \nData.Source\n, a \nData.Sink\n needs to \"register\" the types of streaming it supports, it does so through the following definition:\n\n\n\n\nData.streamtypes(::Type{MyPkg.Sink}) = [Data.Field[, Data.Column]]\n; \"registers\" the streaming preferences for \nMyPkg.Sink\n. A \nSink\n type should list the stream type or types it supports. If the \nSink\n supports streaming of multiple types, it should list them in order of preference (i.e. the more natural or performant type first).\n\n\n\n\nA \nData.Sink\n should also implement specific forms of constructors that allow convenience in many higher-level streaming functions:\n\n\n\n\nMyPkg.Sink{T \n: Data.StreamType}(source, ::Type{T}, append::Bool, args...)\n; given an instance of a \nData.Source\n, the type of streaming \nT\n, whether the user desires to append \nsource\n or not, and any necessary \nargs...\n, construct an appropriate instance of \nMyPkg.Sink\n ready to receive data from \nsource\n. The \nappend\n argument allows an already existing sink file/source to \"reset\" itself if the user does not desire to append.\n\n\nMyPkg.Sink{T \n: Data.StreamType}(sink, source, ::Type{T}, append::Bool)\n; similar to above, but instead of constructing a new \nSink\n, an existing \nSink\n is given as a first argument, which may be modified before being returned, ready to receive data from \nsource\n.\n\n\n\n\nSimilar to \nData.Source\n, a \nData.Sink\n also needs to implement it's own \nstream\n method that indicates how it receives data.\n\n\nA \nData.Sink\n supports \nfield-based\n streaming by optionally defining:\n\n\n\n\nOPTIONAL: \nData.open!(sink::MyPkg.Sink, source)\n: typically, any necessary \nData.Sink\n setup should be accomplished in it's own constructors (\nMyPkg.Sink()\n methods), but there are also cases tied specifically to the streaming process where certain actions need to be taken right before streaming begins. If a \nData.Sink\n needs to perform this kind of action, it can overload \nData.open!(sink::MyPkg.Sink, source)\n\n\nOPTIONAL: \nData.cleanup!(sink::MyPkg.Sink)\n: certain \nData.Sink\n, like databases, may need to protect against inconvenient or dangerous \"states\" if there happens to be an error while streaming. \nData.cleanup!\n provides the sink a way to rollback a transaction or other kind of cleanup if an error occurs during streaming\n\n\nOPTIONAL: \nData.flush!(sink::MyPkg.Sink)\n: similar to \nData.open!\n, a \nData.Sink\n may wish to perform certain actions once the streaming of a single \nData.Source\n has finished. Note however, that a \nData.Sink\n should still be ready to receive more data after a call to \nData.stream!\n has finished. Only once a call to \nData.close!(sink)\n has been made should a sink fully commit/close resources for good.\n\n\nOPTIONAL: \nData.close!(sink::MyPkg.Sink)\n: as noted above, \nData.close!\n is defined to allow a sink to fully commit all streaming results and close/destroy any necessary resources.\n\n\n\n\nThe only method that is absolutely required is:\n\n\n\n\nREQUIRED: \nData.streamfield!{T}(sink::MyPkg.Sink, source, ::Type{T}, row, col, cols[, sinkrows])\n: Given a \nrow\n and \ncol\n, a \nData.Sink\n should first call \nData.getfield(source, T, row, col)\n to get the \nData.Source\n value for that \nrow\n and \ncol\n, and then store the value appropriately. The type of the value retrieved is given by \nT\n, which may be \nNullable{T}\n. Also provided are the total number of columns \ncols\n as well as the number of rows a sink began with as \nsinkrows\n. These arguments are passed for efficiency since they can be calculated once at the beginning of a \nData.stream!\n and used quickly for many calls to \nData.streamfield!\n.\n\n\n\n\nA \nData.Sink\n supports \ncolumn-based\n streaming by defining:\n\n\n\n\nData.streamcolumn!{T}(sink::MyPkg.Sink, source, ::Type{T}, col, row) =\n # of rows streamed\n: Given a column number \ncol\n, a \nData.Sink\n should first call \nData.getcolumn(source, T, col)\n to receive the column of data from the \nData.Source\n before storing it appropriately. The type of the column is given by \nT\n. Also provided is the number of rows \nrow\n that have been streamed so far. This method should return the # of rows that were present in the column streamed from \nData.Source\n so that the total # of streamed rows can be tracked accurately.\n\n\n\n\n\n\nData.Schema\n\n\n#\n\n\nDataStreams.Data.Schema\n \n \nType\n.\n\n\nA \nData.Schema\n describes a tabular dataset (i.e. a set of optionally named, typed columns with records as rows) \nData.Schema\n allow \nData.Source\n and \nData.Sink\n to talk to each other and prepare to provide/receive data through streaming. \nData.Schema\n fields include:\n\n\n\n\nData.header(schema)\n to return the header/column names in a \nData.Schema\n\n\nData.types(schema)\n to return the column types in a \nData.Schema\n; \nNullable{T}\n indicates columns that may contain missing data (null values)\n\n\nData.size(schema)\n to return the (# of rows, # of columns) in a \nData.Schema\n\n\n\n\nData.Source\n and \nData.Sink\n interfaces both require that \nData.schema(source_or_sink)\n be defined to ensure that other \nData.Source\n/\nData.Sink\n can work appropriately.\n\n\nsource", 
            "title": "Home"
        }, 
        {
            "location": "/#datastreamsjl", 
            "text": "The  DataStreams.jl  package aims to define a generic and performant framework for the transfer of \"table-like\" data. (i.e. data that can, at least in some sense, be described by rows and columns).  The framework achieves this by defining interfaces (i.e. a group of methods) for  Data.Source  types and methods to describe how they \"provide\" data; as well as  Data.Sink  types and methods around how they \"receive\" data. This allows  Data.Source s and  Data.Sink s to implement their interfaces separately, without needing to be aware of each other. The end result is an ecosystem of packages that \"automatically\" talk with each other, with adding an additional package not requiring changes to existing packages.  Packages can have a single julia type implement both the  Data.Source  and  Data.Sink  interfaces, or two separate types can implement them separately. For examples of interface implementations, see some of the packages below:  Data.Source  implementations:   CSV.Source  SQLite.Source  DataFrame  ODBC.Source   Data.Sink  implementations:   CSV.Sink  SQLite.Sink  DataFrame  ODBC.Sink", 
            "title": "DataStreams.jl"
        }, 
        {
            "location": "/#datasource-interface", 
            "text": "The  Data.Source  interface requires the following definitions, where  MyPkg  would represent a package wishing to implement the interface:   Data.schema(::MyPkg.Source) =  Data.Schema ; get the  Data.Schema  of a  Data.Source . Typically the  Source  type will store the  Data.Schema  directly, but this isn't strictly required. See  ?Data.Schema  or docs below for more information on  Data.Schema  Data.isdone(::MyPkg.Source, row, col) =  Bool ; indicates whether the  Data.Source  will be able to provide a value at a given a  row  and  col .   Optional definition:   Data.reference(::MyPkg.Source) =  Vector{UInt8} ; Sometimes, a  Source  needs the  Sink  to keep a reference to memory to keep a data structure valid. A  Source  can implement this method to return a  Vector{UInt8}  that the  Sink  will need to handle appropriately.   A  Data.Source  also needs to \"register\" the type (or types) of streaming it supports. Currently defined streaming types in the DataStreams framework include:   Data.Field : a field is the intersection of a specific row and column; this type of streaming will traverse the \"table\" structure by row, accessing each column on each row  Data.Column : this type of streaming will provide entire columns at a time   A  Data.Source  formally supports  field-based  streaming by defining the following:   Data.streamtype(::Type{MyPkg.Source}, ::Type{Data.Field}) = true ; declares that  MyPkg.Source  supports field-based streaming  Data.getfield{T}(::MyPkg.Source, ::Type{Nullable{T}}, row, col) =  Nullable{T} ; returns a value of type  Nullable{T}  given a specific  row  and  col  from  MyPkg.Source  Data.getfield{T}(::MyPkg.Source, ::Type{T}, row, col) =  T ; returns a value of type  T  given a specific  row  and  col  from  MyPkg.Source   And for column-based streaming:   Data.streamtype(::Type{MyPkg.Source}, ::Type{Data.Column}) = true  Data.getcolumn{T}(::Data.Source, ::Type{T}, col) =  Vector{T} ; Given a type  T , returns column #  col  of a  Data.Source  as a  Vector{T}  Data.getcolumn{T}(::Data.Source, ::Type{Nullable{T}}, col) =  NullableVector{T} ; Given a type  Nullable{T} , returns column #  col  of a  Data.Source  as a  NullableVector{T}", 
            "title": "Data.Source Interface"
        }, 
        {
            "location": "/#datasink-interface", 
            "text": "Similar to a  Data.Source , a  Data.Sink  needs to \"register\" the types of streaming it supports, it does so through the following definition:   Data.streamtypes(::Type{MyPkg.Sink}) = [Data.Field[, Data.Column]] ; \"registers\" the streaming preferences for  MyPkg.Sink . A  Sink  type should list the stream type or types it supports. If the  Sink  supports streaming of multiple types, it should list them in order of preference (i.e. the more natural or performant type first).   A  Data.Sink  should also implement specific forms of constructors that allow convenience in many higher-level streaming functions:   MyPkg.Sink{T  : Data.StreamType}(source, ::Type{T}, append::Bool, args...) ; given an instance of a  Data.Source , the type of streaming  T , whether the user desires to append  source  or not, and any necessary  args... , construct an appropriate instance of  MyPkg.Sink  ready to receive data from  source . The  append  argument allows an already existing sink file/source to \"reset\" itself if the user does not desire to append.  MyPkg.Sink{T  : Data.StreamType}(sink, source, ::Type{T}, append::Bool) ; similar to above, but instead of constructing a new  Sink , an existing  Sink  is given as a first argument, which may be modified before being returned, ready to receive data from  source .   Similar to  Data.Source , a  Data.Sink  also needs to implement it's own  stream  method that indicates how it receives data.  A  Data.Sink  supports  field-based  streaming by optionally defining:   OPTIONAL:  Data.open!(sink::MyPkg.Sink, source) : typically, any necessary  Data.Sink  setup should be accomplished in it's own constructors ( MyPkg.Sink()  methods), but there are also cases tied specifically to the streaming process where certain actions need to be taken right before streaming begins. If a  Data.Sink  needs to perform this kind of action, it can overload  Data.open!(sink::MyPkg.Sink, source)  OPTIONAL:  Data.cleanup!(sink::MyPkg.Sink) : certain  Data.Sink , like databases, may need to protect against inconvenient or dangerous \"states\" if there happens to be an error while streaming.  Data.cleanup!  provides the sink a way to rollback a transaction or other kind of cleanup if an error occurs during streaming  OPTIONAL:  Data.flush!(sink::MyPkg.Sink) : similar to  Data.open! , a  Data.Sink  may wish to perform certain actions once the streaming of a single  Data.Source  has finished. Note however, that a  Data.Sink  should still be ready to receive more data after a call to  Data.stream!  has finished. Only once a call to  Data.close!(sink)  has been made should a sink fully commit/close resources for good.  OPTIONAL:  Data.close!(sink::MyPkg.Sink) : as noted above,  Data.close!  is defined to allow a sink to fully commit all streaming results and close/destroy any necessary resources.   The only method that is absolutely required is:   REQUIRED:  Data.streamfield!{T}(sink::MyPkg.Sink, source, ::Type{T}, row, col, cols[, sinkrows]) : Given a  row  and  col , a  Data.Sink  should first call  Data.getfield(source, T, row, col)  to get the  Data.Source  value for that  row  and  col , and then store the value appropriately. The type of the value retrieved is given by  T , which may be  Nullable{T} . Also provided are the total number of columns  cols  as well as the number of rows a sink began with as  sinkrows . These arguments are passed for efficiency since they can be calculated once at the beginning of a  Data.stream!  and used quickly for many calls to  Data.streamfield! .   A  Data.Sink  supports  column-based  streaming by defining:   Data.streamcolumn!{T}(sink::MyPkg.Sink, source, ::Type{T}, col, row) =  # of rows streamed : Given a column number  col , a  Data.Sink  should first call  Data.getcolumn(source, T, col)  to receive the column of data from the  Data.Source  before storing it appropriately. The type of the column is given by  T . Also provided is the number of rows  row  that have been streamed so far. This method should return the # of rows that were present in the column streamed from  Data.Source  so that the total # of streamed rows can be tracked accurately.", 
            "title": "Data.Sink Interface"
        }, 
        {
            "location": "/#dataschema", 
            "text": "#  DataStreams.Data.Schema     Type .  A  Data.Schema  describes a tabular dataset (i.e. a set of optionally named, typed columns with records as rows)  Data.Schema  allow  Data.Source  and  Data.Sink  to talk to each other and prepare to provide/receive data through streaming.  Data.Schema  fields include:   Data.header(schema)  to return the header/column names in a  Data.Schema  Data.types(schema)  to return the column types in a  Data.Schema ;  Nullable{T}  indicates columns that may contain missing data (null values)  Data.size(schema)  to return the (# of rows, # of columns) in a  Data.Schema   Data.Source  and  Data.Sink  interfaces both require that  Data.schema(source_or_sink)  be defined to ensure that other  Data.Source / Data.Sink  can work appropriately.  source", 
            "title": "Data.Schema"
        }
    ]
}